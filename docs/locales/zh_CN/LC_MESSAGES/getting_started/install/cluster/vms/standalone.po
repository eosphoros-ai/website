# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023, csunny
# This file is distributed under the same license as the DB-GPT package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2023.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: DB-GPT üëèüëè 0.3.9\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-10-17 17:24+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"

#: ../../getting_started/install/cluster/vms/standalone.md:1
#: 40af95d327574e5ea9a6c29f68a7709c
msgid "Standalone Deployment"
msgstr ""

#: ../../getting_started/install/cluster/vms/standalone.md:5
#: 7ef23971a0d2415a857d5eb9c4d955ac
msgid "Install Prepare"
msgstr ""

#: ../../getting_started/install/cluster/vms/standalone.md:12
#: f3cd2941fa2d49d686fc246237f82e68
msgid "Create conda environment"
msgstr ""

#: ../../getting_started/install/cluster/vms/standalone.md:20
#: 589d80d5d97044ee93747091904583c5
msgid "Install Default Requirements"
msgstr ""

#: ../../getting_started/install/cluster/vms/standalone.md:26
#: 1d151e72660644e7b43084ffccb99598
msgid "Download and Prepare LLM Model and Embedding Model"
msgstr ""

#: ../../getting_started/install/cluster/vms/standalone.md:28
#: 4443c83f8dfa4fdba30929f1e5ecf619
msgid "If you don't have high performance hardware server"
msgstr ""

#: ../../getting_started/install/cluster/vms/standalone.md:30
#: 33a6ee878a4a467d8bcfe5dfbdcbe184
msgid "you can use openai api, tongyi api , bard api, etc."
msgstr ""

#: ../../getting_started/install/cluster/vms/standalone.md:39
#: 7efdb99bc36d42819b1fcd1341b45eef
msgid "set proxy api in .env"
msgstr ""

#: ../../getting_started/install/cluster/vms/standalone.md:48
#: 50154ece70bc421ebe7ac05966369bc8
msgid "If you have high performance hardware server"
msgstr ""

#: ../../getting_started/install/cluster/vms/standalone.md:62
#: 4f3696ed069a4a84b2d794593df23765
msgid "Start all services with a single command."
msgstr ""

#: ../../getting_started/install/cluster/vms/standalone.md:67
#: f5f671962cb14a10aba34c4274d2fc2c
msgid ""
"By default, the \"dbgpt start webserver\" command will start the "
"Webserver, Model Controller, and Model Worker in a single Python process."
" Here, we specify the service to be started on port 6006."
msgstr ""

#: ../../getting_started/install/cluster/vms/standalone.md:69
#: 4883221a356843f6a6335c25847aecd2
msgid ""
"View and validate the model service in the command line, you can use the "
"following commands"
msgstr ""

#: ../../getting_started/install/cluster/vms/standalone.md:70
#: 1346eb55d7c647be90a90a867ba04ec3
msgid ""
"1.list the started model services and deployed Model Workers, you can use"
" the following command"
msgstr ""

#: ../../getting_started/install/cluster/vms/standalone.md:74
#: 8ab332ebce554758952dbe85c68330a9
msgid "output is:"
msgstr ""

#: ../../getting_started/install/cluster/vms/standalone.md:83
#: efb460bbb70842218f5c056cf05ba1a0
msgid "The WorkerManager is the management process for Model Workers"
msgstr ""

#: ../../getting_started/install/cluster/vms/standalone.md:85
#: 10e5b79f3d914ee3974b1a0d07962fe2
msgid ""
"validate the deployed model in the command line, you can use the "
"following command"
msgstr ""

#: ../../getting_started/install/cluster/vms/standalone.md:89
#: 39d062e7fea948949c1c5c099893f308
msgid ""
"Then an interactive page will be launched where you can have a "
"conversation with the deployed LLM in the terminal."
msgstr ""

